{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "sigopt_experiment_and_optimization_demo.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFJgv_3P4Bkl"
   },
   "source": [
    "#SigOpt Experiment And Optimization Demo\n",
    "\n",
    "In this notebook, you will learn how to:\n",
    "\n",
    "* Install the SigOpt python client\n",
    "* Set your SigOpt API token\n",
    "* Create your first project\n",
    "* Instrument your model\n",
    "* Create your first Experiment and optimize your model metric with SigOpt\n",
    "* Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5s2PjpUT8T8"
   },
   "source": [
    "## Install `sigopt` Python Client\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GStrnIw7S_ra"
   },
   "source": [
    "!pip install sigopt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPHmUxsBUO74"
   },
   "source": [
    "## Set Your API Token\n",
    "\n",
    "Once you've installed SigOpt, you need to add your SigOpt API token.\n",
    "\n",
    "If you don't have an account yet, sign up for a free account at [app.sigopt.com/signup](https://app.sigopt.com/signup).\n",
    "\n",
    "To get your API token, visit https://app.sigopt.com/tokens/info. This page is accessible from anywhere in the app when you click on your name in the top right corner, and select \"API Tokens\".\n",
    "\n",
    "<img src=\"https://public.sigopt.com/get-started-notebooks/v1/find-api-token.gif\" width=\"900\"/>\n",
    "\n",
    "Once you have your API token, run the code cell below to authenticate, configure SigOpt and load the notebook integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4TA9RJm4UFPu"
   },
   "source": [
    "!sigopt config\n",
    "import sigopt\n",
    "%load_ext sigopt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1aUAYtzhhml"
   },
   "source": [
    "## Instrument Your Model\n",
    "\n",
    "Letâ€™s start out by importing some useful libraries and load our data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EPjIZgbdhjCt"
   },
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn import datasets\n",
    "import numpy\n",
    "import sigopt\n",
    "import time"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AAB9zZWtWFH3"
   },
   "source": [
    "DATASET_NAME = \"Sklearn Wine\"\n",
    "FEATURE_ENG_PIPELINE_NAME = \"Sklearn Standard Scalar\"\n",
    "PREDICTION_TYPE = \"Multiclass\"\n",
    "DATASET_SRC = \"sklearn.datasets\"\n",
    "\n",
    "def get_data():\n",
    "\n",
    "  \"\"\"\n",
    "  Load sklearn wine dataset, and scale features to be zero mean, unit variance.\n",
    "  One hot encode labels (3 classes), to be used by sklearn OneVsRestClassifier.\n",
    "  \"\"\"\n",
    "\n",
    "  data = datasets.load_wine()\n",
    "  X = data[\"data\"]\n",
    "  y = data[\"target\"]\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "  enc = OneHotEncoder()\n",
    "  Y = enc.fit_transform(y[:, numpy.newaxis]).toarray()\n",
    "\n",
    "  return (X_scaled, Y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81yDzXfShoZ_"
   },
   "source": [
    "We now create our model function; `evaluate_xgboost_model` that instantiates one xgboost classifier per class in our 3-class dataset, and evaluate the one-vs-rest classifier set on `number_of_cross_val_folds` before reporting the mean score and the wall-clock time to instantiate and train the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "n-slS09RhACg"
   },
   "source": [
    "MODEL_NAME = \"OneVsRestClassifier(XGBoostClassifier)\"\n",
    "\n",
    "def evaluate_xgboost_model(X, y,\n",
    "                           number_of_cross_val_folds=5,\n",
    "                           max_depth=6,\n",
    "                           learning_rate=0.3,\n",
    "                           min_split_loss=0):\n",
    "    t0 = time.time()\n",
    "    classifier = OneVsRestClassifier(XGBClassifier(\n",
    "        objective = \"binary:logistic\",\n",
    "        max_depth =    max_depth,\n",
    "        learning_rate = learning_rate,\n",
    "        min_split_loss = min_split_loss,\n",
    "        use_label_encoder=False,\n",
    "        verbosity = 0\n",
    "    ))\n",
    "    cv_accuracies = cross_val_score(classifier, X, y, cv=number_of_cross_val_folds)\n",
    "    tf = time.time()\n",
    "    training_and_validation_time = (tf-t0)\n",
    "    return numpy.mean(cv_accuracies), training_and_validation_time"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxk4TmsgFHwq"
   },
   "source": [
    "The second function `run_and_track_in_sigopt` uses SigOpt methods to log and track key model information including:\n",
    "* the type of model used (`sigopt.log_model`),\n",
    "* the name of the dataset (`sigopt.log_dataset`),\n",
    "* the hyperparameters used to build the model that will be tuned during the Experiment, including their default value (`sigopt.params.setdefault`),\n",
    "* the hyperparameters used to build the model that will just be tracked, but not tuned during the Experiment (`sigopt.params.[PARAMETER_NAME]`),\n",
    "* various attributes relevant to the model (`sigopt.log_metadata`) and\n",
    "* the model output metrics (`sigopt.log_metric`)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7ynaKU7zhrGm"
   },
   "source": [
    "def run_and_track_in_sigopt():\n",
    "\n",
    "    (features, labels) = get_data()\n",
    "\n",
    "    sigopt.log_dataset(DATASET_NAME)\n",
    "    sigopt.log_metadata(key=\"Dataset Source\", value=DATASET_SRC)\n",
    "    sigopt.log_metadata(key=\"Feature Eng Pipeline Name\", value=FEATURE_ENG_PIPELINE_NAME)\n",
    "    sigopt.log_metadata(key=\"Dataset Rows\", value=features.shape[0]) # assumes features X are like a numpy array with shape\n",
    "    sigopt.log_metadata(key=\"Dataset Columns\", value=features.shape[1])\n",
    "    sigopt.log_metadata(key=\"Execution Environment\", value=\"Colab Notebook\")\n",
    "    sigopt.log_model(MODEL_NAME)\n",
    "\n",
    "    sigopt.params.setdefault(\"max_depth\", numpy.random.randint(low=3, high=15, dtype=int))\n",
    "    sigopt.params.setdefault(\"learning_rate\", numpy.random.random(size=1)[0])\n",
    "    sigopt.params.setdefault(\"min_split_loss\", numpy.random.random(size=1)[0]*10)\n",
    "\n",
    "    args = dict(X=features,\n",
    "                y=labels,\n",
    "                max_depth=sigopt.params.max_depth,\n",
    "                learning_rate=sigopt.params.learning_rate,\n",
    "                min_split_loss=sigopt.params.min_split_loss)\n",
    "\n",
    "    mean_accuracy, training_and_validation_time = evaluate_xgboost_model(**args)\n",
    "\n",
    "    sigopt.log_metric(name='accuracy', value=mean_accuracy)\n",
    "    sigopt.log_metric(name='training and validation time (s)', value=training_and_validation_time)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfNhrTE27dJO"
   },
   "source": [
    "## Define Your Experiment Configuration\n",
    "\n",
    "A SigOpt Experiment is an automated search of your model's hyperparameter space. A SigOpt Experiment works as follows:\n",
    "\n",
    "<img src=\"https://static.sigopt.com/b/d4ed0c2c4741dfb05b18877368ba2732ac6f26fd/static/img/landing/homepage_graph1.svg\" width=\"900\"/>\n",
    "\n",
    "With the `experiment` command below, you set your Experiment configuration by giving it a name, defining accuracy as the metric to maximize, and finally setting your hyperparameter space by instructing SigOpt to explore values within set boundaries. In our case, we ask SigOpt's optimization engine to return values for max-depth within 3 and 12 and a learning rate bewteen 0 and 1. Finally, the budget defines how many time we'll train our model. In this case, we will train our model 20 times, representing 20 SigOpt Runs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BckdXB037d4G"
   },
   "source": [
    "%%experiment\n",
    "{\n",
    "    'name': 'XGBoost Optimization',\n",
    "    'metrics': [\n",
    "        {\n",
    "            'name': 'accuracy',\n",
    "            'strategy': 'optimize',\n",
    "            'objective': 'maximize',\n",
    "        }\n",
    "    ],\n",
    "    'parameters': [\n",
    "        {\n",
    "            'name': 'max_depth',\n",
    "            'type': 'int',\n",
    "            'bounds': {'min': 3, 'max': 12}\n",
    "        },\n",
    "        {\n",
    "            'name': 'learning_rate',\n",
    "            'type': 'double',\n",
    "            'bounds': {'min': 0.0, 'max': 1.0}\n",
    "        }\n",
    "    ],\n",
    "    'budget': 20\n",
    "}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxcokWV1-7jZ"
   },
   "source": [
    "SigOpt will conveniently output the Experiment link in the terminal so you can check your Experiment was created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8imk4IQlWlx"
   },
   "source": [
    "## Execute SigOpt Optimization\n",
    "Let's run our optimization using the `%%optimize` magic command. SigOpt will pick up the `experiment` configuration automatically  and conveniently output links in the terminal to the current Run on our web application."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ktWWkiQxoaix"
   },
   "source": [
    "%%optimize My_First_Optimization\n",
    "run_and_track_in_sigopt()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gq2TkUqBz_aP"
   },
   "source": [
    "## Visualize Results\n",
    "\n",
    "You can click on any of the Run links above and view your completed Run in our web application. Here's a view of a Run page:\n",
    "\n",
    "<img src=\"https://public.sigopt.com/get-started-notebooks/v1/view-run-page.gif\" width=\"900\"/>\n",
    "\n",
    "The charts on the Run page show how it compares on key metrics with other Runs in the same project.\n",
    "\n",
    "From the Run page, click on the Project Name at the top of the page to navigate to your project. At the project level, you can compare Runs, sort and filter through your Runs and view useful charts to gain insight into everything you've tried.\n",
    "\n",
    "<img src=\"https://public.sigopt.com/get-started-notebooks/v1/sort-runs-in-project.gif\" width=\"900\"/>\n",
    "\n",
    "From the Project page, click on the Experiments tab, and click on the Experiment you just created. The Experiment Summary page features the Experiment best value and shows Experiment improvement in a grapth that plots the best recorded model metric throughout the course of your Experiment.\n",
    "\n",
    "The Experiment Analysis page features additional visualizations to help you gain insight into your optimization problem, including Paramater Importance, Parallel Coordinates, and interactive graphs that help you create 2D and 3D representations of your metric and parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd67ldz8vTYA"
   },
   "source": [
    "## From Experiments To Runs\n",
    "\n",
    "In this demo we've covered the recommended way to instrument and optimize your model, and visualize your results with SigOpt. You learned that Experiments are collections of Runs that search through a defined parameter space for one or more metrics. Check out this ([notebook](https://colab.research.google.com/github/sigopt/sigopt-examples/blob/master/get-started/sigopt_runs_demo.ipynb/)) for a closer look at a single Run, and see how to track one-off Runs without creating an Experiment."
   ]
  }
 ]
}
