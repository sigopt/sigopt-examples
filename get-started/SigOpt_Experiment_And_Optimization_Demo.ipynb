{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SigOpt_Experiment_And_Optimization_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFJgv_3P4Bkl"
      },
      "source": [
        "#SigOpt Experiment And Optimization Demo\n",
        "\n",
        "In this tutorial, you will learn how to:\n",
        "\n",
        "* Install the SigOpt python client\n",
        "* Set your SigOpt API token\n",
        "* Create your first project\n",
        "* Instrument your model\n",
        "* Create your first experiment and optimize your model metric with SigOpt\n",
        "* Visualize Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5s2PjpUT8T8"
      },
      "source": [
        "## Install `sigopt` Python Client\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GStrnIw7S_ra"
      },
      "source": [
        "! pip install sigopt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPHmUxsBUO74"
      },
      "source": [
        "## Set Your API Token\n",
        "\n",
        "Once you've installed SigOpt, you need to add your SigOpt API token.\n",
        "\n",
        "To get your API token, visit https://app.sigopt.com/tokens/info. This page is accessible from anywhere in the app when you click on your name in the top right corner, and select \"API Tokens\".\n",
        "\n",
        "If you don't have an account yet, sign up for a free at [app.sigopt.com/signup](https://app.sigopt.com/signup).\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/qTLPiuNaCfcky1mLy1/giphy.gif\" width=\"900\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TA9RJm4UFPu"
      },
      "source": [
        "MY_API_TOKEN = \"YOUR_API_TOKEN_HERE\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoP3Axs_7x-K"
      },
      "source": [
        "Then configure your connection with SigOpt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kByBIJOlUeti"
      },
      "source": [
        "from sigopt import Connection\n",
        "conn = Connection(client_token=MY_API_TOKEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEEu1lImVGDD"
      },
      "source": [
        "## Create Your Project\n",
        "\n",
        "Experiment and training runs are created within projects. The project allows you to sort and filter your experiment runs and view useful charts to gain insights into everything you've tried, including model optimization.\n",
        "\n",
        "Feel free to edit the name of your project below. Note that the API token is also set as an environment variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB2-tngFVOjB"
      },
      "source": [
        "import os\n",
        "os.environ['SIGOPT_API_TOKEN'] = MY_API_TOKEN\n",
        "os.environ['SIGOPT_PROJECT'] = \"SigOpt_Optimize_XGB_Classifier\"\n",
        "%load_ext sigopt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1aUAYtzhhml"
      },
      "source": [
        "## Instrument Your Model\n",
        "\n",
        "Letâ€™s start out by importing some useful libraries and load our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPjIZgbdhjCt"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn import datasets\n",
        "import numpy\n",
        "import sigopt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAB9zZWtWFH3"
      },
      "source": [
        "DATASET_NAME = \"Sklearn Wine\"\n",
        "FEATURE_ENG_PIPELINE_NAME = \"Sklearn Standard Scalar\"\n",
        "PREDICTION_TYPE = \"Multiclass\"\n",
        "DATASET_SRC = \"sklearn.datasets\"\n",
        "\n",
        "def get_data():\n",
        "  \n",
        "  \"\"\"\n",
        "  Load sklearn wine dataset, and scale features to be zero mean, unit variance.\n",
        "  One hot encode labels (3 classes), to be used by sklearn OneVsRestClassifier. \n",
        "  \"\"\"\n",
        " \n",
        "  data = datasets.load_wine()\n",
        "  X = data[\"data\"]\n",
        "  y = data[\"target\"]\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "  enc = OneHotEncoder()\n",
        "  Y = enc.fit_transform(y[:, numpy.newaxis]).toarray()\n",
        "\n",
        "  return (X_scaled, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81yDzXfShoZ_"
      },
      "source": [
        "We now create our model function; `evaluate_xgboost_model` that instantiates one xgboost classifier per class in our 3-class dataset, and evaluate the one-vs-rest classifier set on `number_of_cross_val_folds` before reporting the mean score and the wall-clock time to instantiate and train the models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-slS09RhACg"
      },
      "source": [
        "MODEL_NAME = \"OneVsRestClassifier(XGBoostClassifier)\"\n",
        "\n",
        "def evaluate_xgboost_model(X, y, \n",
        "                           number_of_cross_val_folds=5,\n",
        "                           max_depth=6,\n",
        "                           learning_rate=0.3,\n",
        "                           min_split_loss=0):\n",
        "    t0 = time.time()\n",
        "    classifier = OneVsRestClassifier(XGBClassifier(\n",
        "        objective = \"binary:logistic\",\n",
        "        max_depth =    max_depth,\n",
        "        learning_rate = learning_rate,\n",
        "        min_split_loss = min_split_loss,\n",
        "        use_label_encoder=False,\n",
        "        verbosity = 0\n",
        "    ))\n",
        "    cv_accuracies = cross_val_score(classifier, X, y, cv=number_of_cross_val_folds)\n",
        "    tf = time.time()\n",
        "    training_and_validation_time = (tf-t0)\n",
        "    return numpy.mean(cv_accuracies), training_and_validation_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxk4TmsgFHwq"
      },
      "source": [
        "The second function `run_and_track_in_sigopt` uses SigOpt methods to log and track key model information including:\n",
        "* the type of model used (`sigopt.log_model`),\n",
        "* the name of the dataset (`sigopt.log_dataset`),\n",
        "* the hyperparameters used to build the model (`sigopt.get_parameter`),\n",
        "* various attributes relevant to the model (`sigopt.log_metadata`) and\n",
        "* the model output metrics (`sigopt.log_metric`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ynaKU7zhrGm"
      },
      "source": [
        "def run_and_track_in_sigopt():\n",
        "\n",
        "    (features, labels) = get_data()\n",
        "\n",
        "    sigopt.log_dataset(DATASET_NAME)\n",
        "    sigopt.log_metadata(key=\"Dataset Source\", value=DATASET_SRC)\n",
        "    sigopt.log_metadata(key=\"Feature Eng Pipeline Name\", value=FEATURE_ENG_PIPELINE_NAME)\n",
        "    sigopt.log_metadata(key=\"Dataset Rows\", value=features.shape[0]) # assumes features X are like a numpy array with shape\n",
        "    sigopt.log_metadata(key=\"Dataset Columns\", value=features.shape[1])\n",
        "    sigopt.log_metadata(key=\"Execution Environment\", value=\"Colab Notebook\")\n",
        "    sigopt.log_model(MODEL_NAME)\n",
        "\n",
        "    args = dict(X=features, y=labels,\n",
        "                max_depth = sigopt.get_parameter(\"max_depth\", default = numpy.random.randint(low=3, high=15, dtype=int)),\n",
        "                learning_rate = sigopt.get_parameter(\"learning_rate\", default = numpy.random.random(size=1)[0]),\n",
        "                min_split_loss = sigopt.get_parameter(\"min_split_loss\", default = numpy.random.random(size=1)[0]*10))\n",
        "\n",
        "    mean_accuracy, training_and_validation_time = evaluate_xgboost_model(**args)\n",
        "\n",
        "    sigopt.log_metric(name='accuracy', value=mean_accuracy)\n",
        "    sigopt.log_metric(name='training and validation time (s)', value=training_and_validation_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfNhrTE27dJO"
      },
      "source": [
        "## Define Your Experiment Configuration\n",
        "\n",
        "An Experiment is a set of parameters and at least one metric that you would like to maximize or minimize. With the `experiment` command below, you set your experiment configuration by giving it a name, defining accuracy as the metric to maximize, and finally setting your hyperparameter space by instructing SigOpt to explore values within set boundaries. In our case, we ask SigOpt's optimization engine to return values for max-depth within 3 and 12, a learning rate bewteen 0 and a and a min_split_loss between 0 and 10. Finally, the observation budget defines how many time we'll train our model. In this case, we will run 20 training runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BckdXB037d4G"
      },
      "source": [
        "%%experiment\n",
        "{\n",
        "    'name': 'XGBoost Optimization',\n",
        "    'metrics': [\n",
        "        {\n",
        "            'name': 'accuracy',\n",
        "            'strategy': 'optimize',\n",
        "            'objective': 'maximize',\n",
        "        }\n",
        "    ],\n",
        "    'parameters': [\n",
        "        {\n",
        "            'name': 'max_depth',\n",
        "            'type': 'int',\n",
        "            'bounds': {'min': 3, 'max': 12}\n",
        "        },\n",
        "        {\n",
        "            'name': 'learning_rate',\n",
        "            'type': 'double',\n",
        "            'bounds': {'min': 0.0, 'max': 1.0}\n",
        "        },\n",
        "        {\n",
        "            'name': 'min_split_loss',\n",
        "            'type': 'double',\n",
        "            'bounds': {'min': 0.0, 'max': 10.0}\n",
        "        }\n",
        "    ],\n",
        "    'observation_budget': 20\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxcokWV1-7jZ"
      },
      "source": [
        "SigOpt will conveniently output the Experiment link in the terminal so you can check your experiment was created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8imk4IQlWlx"
      },
      "source": [
        "## Execute SigOpt Optimization \n",
        "Let's run our optimization using the `%%optimize` magic command. SigOpt will pick up the `experiment` configuration automatically  and conveniently output links in the terminal to the surrent training run on our web application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktWWkiQxoaix"
      },
      "source": [
        "%%optimize My_First_Optimization\n",
        "run_and_track_in_sigopt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq2TkUqBz_aP"
      },
      "source": [
        "## Visualize Results\n",
        "\n",
        "You can click on any of the run links above and view your completed run in our web application. Here's a view of a training run page:\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/dofe86JH6nbPVbJyzy/giphy.gif\" width=\"600\"/>\n",
        "\n",
        "The charts on the training run page show how it compares on key metrics with other runs in the same project.\n",
        "\n",
        "From the Run page, click on the Project Name at the top of the page to navigate to your project. At the project level, you can compare training runs, sort and filter through your training runs and view useful charts to gain insight into everything you've tried.\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/GY3CyrLTecBD9oCtce/giphy.gif\" width=\"600\"/>\n",
        "\n",
        "From the Project page, click on the Experiments tab, and click on the experiment you just created. The experiment Summary page features the experiment best value and shows experiment improvement in a grapth that plots the best observed model metric throughout the course of your experiment.\n",
        "\n",
        "The experiment Analyis page features additional visualizations to help you gain insight into your optimization problem, including Paramater Importance, Parallel Coordinates, and interactive graphs that help you create 2D and 3D representation of your metric and parameter space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd67ldz8vTYA"
      },
      "source": [
        "## From Experiments To Training Runs\n",
        "\n",
        "In this demo we've covered the recommended way to instrument and optimize your model, and visualize your results with SigOpt. You learned that experiments are collections of runs that search through a defined parameter space for one or more metrics. Check out this ([notebook](https://colab.research.google.com/github/sigopt/sigopt-examples/blob/master/get-started/sigopt_training_run_demo.ipynb/)) for a closer look at a single training run, and see how to track one-off training runs without creating an experiment. "
      ]
    }
  ]
}